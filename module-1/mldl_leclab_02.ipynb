{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKvsnayIdpcevUJ+elilj8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dyjdlopez/deep-learning-fundamentals/blob/main/module-1/mldl_leclab_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 2: Fundamentals of Linear Algebra for Machine Learning and Data Science (Part 1)\n",
        "### Deep Learning Course 2023\n",
        "$_\\text{Engr. D.J.D Lopez, M.Sc.}$<br>\n",
        "$_\\text{Adjunct Professor, Adamson University}$"
      ],
      "metadata": {
        "id": "HJNZcZL7ff-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Representation\n",
        "\n",
        "Data and information can be stored electronically using digital data. Digital data in its true form is considered quasi-structured data due to its nature-specific interpretability. To make it easier for analysis, data can be re-roganized as structured data."
      ],
      "metadata": {
        "id": "mIk2Tf4wfkXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Algebra\n",
        "A field of mathematics that deals with vector analysis and their transformations.\n",
        "\n",
        "The discussion of linear algebra revolves around vectors, their representations, interpretation, and transformation."
      ],
      "metadata": {
        "id": "SYpQx35oflZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Algebra and Machine Learning\n",
        "\n",
        "Machine learning deals with the analysis of information, linear algebra can be used to model the algorithms and transformation of data to get their **essence** or patterns."
      ],
      "metadata": {
        "id": "vkgYBsnFfojp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's start coding Linear Algebra\n",
        "The idea of doing linear algebra in code is part of computational programming. We take advantage of the logic and arithmetic of linear algebra and code them to apply the theory. We can immediately see the transformation of data and how they are represented.\n",
        "\n",
        "In this discussion, we will be using `numpy` as the main library for computation and `matplotlib` for visualizing the data."
      ],
      "metadata": {
        "id": "l-p4a0L8fqZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(200)"
      ],
      "metadata": {
        "id": "vfOyayLEfkvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectors\n",
        "Vectors are the most fundamental concept in linear algebra. Vectors in the computer science aspect are the collection of **scalars** or numbers; or in the mathematical perspective, these are a representation of a point in space. We can mathematically represent vectors as:\n",
        "$$\\mathbf{v} = \\begin{pmatrix} a_0 & a_1 & a_2 & ... & a_{n-1} & a_n \\end{pmatrix} $$"
      ],
      "metadata": {
        "id": "7uwJ1TuRfx7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a Scalar\n",
        "scalar = 1\n",
        "## in numpy\n",
        "scalar_np = np.array(2)\n",
        "\n",
        "print(scalar)\n",
        "print(scalar_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpislk5cfwGd",
        "outputId": "f27b170c-784f-4586-8dd2-6816a7c86d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a vector in numpy\n",
        "vector = np.array([1,2,3])\n",
        "\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yabgHLuXfzoh",
        "outputId": "72816b52-57b5-41b7-a4b7-dfff54c5df7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrices\n",
        "Matrices are a collection of scalars that could be represented in a lattice-like arrangement with $m$ rows and $n$ columns. It takes on a form like this:\n",
        "$$\\mathbf{M} = \\begin{pmatrix} a_{00} & a_{01} & a_{02} & ...  & a_{0n} \\\\ a_{10} & a_{11} & a_{12} & ... & a_{1n} \\\\ a_{20} & a_{21} & a_{22} & ... & a_{2n} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\ a_{m0} & a_{m1} & a_{m2} & ... & a_{mn} \\end{pmatrix} $$\n"
      ],
      "metadata": {
        "id": "3hVuYP7Af2uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a Matrix (elements)\n",
        "A = np.array([\n",
        "    [1,2,3],\n",
        "    [3,1,0],\n",
        "    [-1,0,2]\n",
        "])\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrCDyH7xf1Hh",
        "outputId": "c4e4f8e9-441b-431b-fbcc-e4cfbff9a4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3],\n",
              "       [ 3,  1,  0],\n",
              "       [-1,  0,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also think that matrices are collections of scaled vectors like this:\n",
        "$$\\mathbf{M} = \\begin{pmatrix} a_0 \\cdot v_0 \\\\ a_1 \\cdot v_1 \\\\ \\vdots \\\\ a_n\\cdot v_n \\end{pmatrix}$$"
      ],
      "metadata": {
        "id": "XyC8rRckf5r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a Matrix (vectors)\n",
        "v1 = np.array([1,2,3])\n",
        "v2 = np.array([3,2,1])\n",
        "v3 = np.array([1,-1,-2])\n",
        "B = np.array([\n",
        "    2*v1,\n",
        "    -1*v2,\n",
        "    0.5*v3\n",
        "])\n",
        "B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HNDw_H_f4ZZ",
        "outputId": "64b33c86-493a-495f-bb79-068d4436b6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2. ,  4. ,  6. ],\n",
              "       [-3. , -2. , -1. ],\n",
              "       [ 0.5, -0.5, -1. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorization\n",
        "The idea of vectorization is coding with linear algebra in mind, this includes the representation of data and the operations that we can do on vectors such as element-wise operations, broadcasting, inner products, and even projections."
      ],
      "metadata": {
        "id": "J4Mv2Z-ogAgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Operations\n",
        "Before we get to fully vectorize code, we need to refresh in performing in operating with vectors. In the following slides, we'll review the arithmetics we can do with vectors, transposition, the inner product, vector norms, projection, and solving linear equations."
      ],
      "metadata": {
        "id": "DqR4RWGigCMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Element-wise Arithmetic\n",
        "The element-wise and scalar arithmetic can be done in Python such as addition, subtraction, multiplication, division, exponentiation, and even other transcendental transformations."
      ],
      "metadata": {
        "id": "Z01LyffHgFfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Element-wise operations\n",
        "A = np.array([\n",
        "    [1,2],\n",
        "    [-1,0]\n",
        "])\n",
        "B = np.array([\n",
        "    [0,1],\n",
        "    [1,0]\n",
        "])"
      ],
      "metadata": {
        "id": "IzqpckVzf7Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Scalar operations\n",
        "k = -1\n",
        "A = np.array([\n",
        "    [1,-1],\n",
        "    [2,3]\n",
        "])"
      ],
      "metadata": {
        "id": "S5w7XUSrgIJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Element-wise vector transformations\n",
        "f = lambda x: np.exp(x)\n",
        "g = lambda x: np.log(x)\n",
        "A = 5*np.ones((2,2))"
      ],
      "metadata": {
        "id": "QdU41TgAgJg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transposition\n",
        "The transposition operation flips the matrix along its diagonal. In mathematical terms it will for some matrix $\\mathbf{M}$ its transposed form will be $\\mathbf{M}^T$:\n",
        "$$\\mathbf{M} = \\begin{pmatrix} a_{00} & a_{01} & a_{02} \\\\ a_{10} & a_{11} & a_{12} \\\\ a_{20} & a_{21} & a_{22}\\end{pmatrix} ; \\mathbf{M}^T = \\begin{pmatrix} a_{00} & a_{10} & a_{20} \\\\ a_{01} & a_{11} & a_{21} \\\\ a_{02} & a_{12} & a_{22}\\end{pmatrix}$$\n"
      ],
      "metadata": {
        "id": "TjioJPiggMsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Transposing a square matrix\n",
        "M = np.random.randint(1,5,(3,3))\n",
        "np.transpose(M)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4R5W2oygLXs",
        "outputId": "6350d26d-76ed-4a47-eaf6-65e11db25400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 1, 1],\n",
              "       [2, 3, 4],\n",
              "       [1, 4, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transposing non-square matrices\n",
        "N = np.random.randint(2,6,(4,3))\n",
        "N.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7ISd7mYgOkh",
        "outputId": "25275407-646a-4156-8df8-4edf5b2ce45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4, 3, 4, 5],\n",
              "       [5, 5, 2, 5],\n",
              "       [3, 4, 3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transposing row/column vectors\n",
        "v = np.random.randint(2,6,(1,3))\n",
        "v.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8xwgePwgPl6",
        "outputId": "7ab9c834-c8e5-4a6f-b833-ff997acddb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [5],\n",
              "       [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inner Product\n",
        "The inner product is one of the most important operations in linear algebra. It solves for the linear combination of the vectors and matrices. The inner product is not always commutative. \n",
        "\n",
        "The inner product of a matrix can be solved only if the number of columns of the first vector is equal to the number of rows in the second vector. So if the first matrix is $\\mathbf{A}$ has a shape of $(m,n)$ and and the second matrix is $\\mathbf{B}$ has a shape of $(i,j)$, then you can perform $AB$ if $n=i$."
      ],
      "metadata": {
        "id": "ZjNmscHhgRDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Row-column inner product\n",
        "A = np.random.randint(1,10,(1,3))\n",
        "B = np.random.randint(1,10,(1,3))"
      ],
      "metadata": {
        "id": "LXjGnxhsgQb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Non-square inner product\n",
        "A = np.random.randint(1,10,(2,3))\n",
        "B = np.random.randint(1,10,(3,2))"
      ],
      "metadata": {
        "id": "3OqL-mk3gTI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Square inner product\n",
        "A = np.random.randint(1,10,(2,2))\n",
        "B = np.random.randint(1,10,(2,2))"
      ],
      "metadata": {
        "id": "WzjggBOSgT_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Vector Norm\n",
        "The norm of a vector describes its magnitude along a dimension. In calculations in machine learning we often use norms in the first and second dimensions, we call these the L1 and L2 norm. The general formula for the vector norm is called the Frobenius norm:\n",
        "$$||\\mathbf{M}||_n = \\Biggl(\\sum^N_{i=0}m_i^n\\Biggr)^{1/n}$$"
      ],
      "metadata": {
        "id": "f5L_kxejgX2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's translate the Frobenius norm as code:\n",
        "def frobenius_norm(n, vector):\n",
        "    n_sum = np.sum(vector**n)\n",
        "    vect_norm = np.power(n_sum,1/n)\n",
        "    return vect_norm"
      ],
      "metadata": {
        "id": "cN6dhpxIgU8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The L1 Norm\n",
        "The L1 norm is also called the Manhattan distance. Using the Frobenius norm, we set the value of $n$ to 1 signifying the dimensionality as 1. So we get:\n",
        "$$||\\mathbf{M}||_1 = \\sum^N_{i=0}m_i$$"
      ],
      "metadata": {
        "id": "zqH46GtPgfVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def l1_norm(vector):\n",
        "    vect_norm = np.sum(vector)\n",
        "    return vect_norm"
      ],
      "metadata": {
        "id": "s85AVm_ugb7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.array([1,1,2])\n",
        "\n",
        "## using our l1 function\n",
        "# l1_norm(v)\n",
        "\n",
        "## using our frobenius norm function\n",
        "# frobenius_norm(1, v)"
      ],
      "metadata": {
        "id": "AeZVPeBlghDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The L2 Norm\n",
        "The L2 norm or the Euclidean norm, shows the vector magnitude in the 2D plane. Using the Frobenius norm, we set the value of $n$ to 2 signifying the dimensionality as 2. So we get:\n",
        "$$||\\mathbf{M}||_n = \\Biggl(\\sum^N_{i=0}m_i\\Biggr)^{1/2} = \\sqrt{\\sum^N_{i=0}m_i}$$"
      ],
      "metadata": {
        "id": "6eo6fbBTgkth"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uE3GgH6Eiva2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_norm(vector):\n",
        "    n_sum = np.dot(vector, vector)\n",
        "    vect_norm = np.sqrt(n_sum)\n",
        "    return vect_norm"
      ],
      "metadata": {
        "id": "HofGLVdQgh1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.array([1,1,2])\n",
        "frobenius_norm(1, v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iob-YewBgmVl",
        "outputId": "9569ce91-fc04-436a-b934-07511b8eb93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy also provides a library for the Frobenius norm. \n",
        "You can check the docs [here](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html)"
      ],
      "metadata": {
        "id": "Slk6W4mdgpNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(v,ord=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoPONtmrgnxx",
        "outputId": "a68bad97-1bb7-4126-a5d4-8e4a12a17f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalized Vectors\n",
        "In most cases, we want matrices to hold unit vectors. Meaning, we would have the values of our vectors only between 0 and 1. To do this we can perform normalization to our vector or matrix $\\mathbf{M}$:\n",
        "$$\\mathbf{M}_{norm} = \\frac{\\mathbf{M}}{||M||}$$"
      ],
      "metadata": {
        "id": "5B_2BEJngryk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_norm(vector):\n",
        "    return vector/np.linalg.norm(vector)"
      ],
      "metadata": {
        "id": "e2mFHwhYgqfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.array([50,32, 13])\n",
        "vector_norm(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4Uerbmygtgt",
        "outputId": "80704f6f-a4af-48ba-8c01-e44c2e1984f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8227736 , 0.52657511, 0.21392114])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint Activity 1"
      ],
      "metadata": {
        "id": "C8c4iulcgv_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine Similarity\n",
        "We can determine the similarity of vectors by measuring the angle between them. We can do this using the cosine similarity theorem. Consider two vectors $A$ and $B$:\n",
        "$$\\cos{\\theta} = \\frac{AB}{||A||\\cdot||B||}$$"
      ],
      "metadata": {
        "id": "09Zti7HVgzbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Case 1\n",
        "In Natural Language Processing, words can be represented by vectors in a process called \"word embeddings\" and vectorization. Supposed we were given a corpus (a piece of text) and we are tasked to determine the similarity of the words **conflagration, mayhem, and cataclysm**. Given in the code below are the vector embeddings of the words, determine the similarities of each word to each other."
      ],
      "metadata": {
        "id": "S2yCGdU7g075"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = np.array([0.0513, 0.9788]) ##conflagration\n",
        "w2 = np.array([0.7540, 0.8824]) ##mayhem\n",
        "w3 = np.array([0.6115, 0.9788]) ##cataclysm"
      ],
      "metadata": {
        "id": "0-UcnallgxmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similarity(a,b):\n",
        "    inner_prod = a@b\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    similarity = inner_prod / (norm_a*norm_b)\n",
        "    return similarity    "
      ],
      "metadata": {
        "id": "knH--M9Ag3uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Brute force\n",
        "words = [w1,w2,w3]\n",
        "for i in range(len(words)):\n",
        "    for j in range(len(words)):\n",
        "        cossim = cos_similarity(words[i], words[j])\n",
        "        print(f'Similarity between w{i} and w{j}: {cossim}')"
      ],
      "metadata": {
        "id": "0j1GewDBg5Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An important property of matrices is their **orthogonality**. Like in geometry, this signifies that the vectors form 90 degrees with each other. Using the idea of cosine similarity, vectors are similar id $\\cos(\\theta) = 1$ which indicates $\\theta = 90$ or $\\frac{\\pi}{2}$. Another property called **orthonormality** tells us that the matrix is orthogonal and normal at the same time."
      ],
      "metadata": {
        "id": "HE4FtMGqg8aP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Inverse\n",
        "The inverse of a matrix is similar to the concept of inverse functions. In a sense, matrices are linear transformations that are a form of function. The inverse of a function can be solved in numerous ways using determinants or co-factors. Since that is already covered in either College-level algebra or Linear Algebra courses, we will skip ahead with the direct implementation. We can then further denote the inverse of a matrix $\\mathbf{M}$ as:\n",
        "$$\\mathbf{M}^{-1}$$\n",
        "With the notion that the matrix inverse is simlilar inverse functions, we can algebraically cancel out matrices in an equation by doing a dot product between a matrix and itself:\n",
        "$$\\mathbf{M}^{-1}\\cdot \\mathbf{M} = I$$"
      ],
      "metadata": {
        "id": "LaczLbMOg-A6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can perform matrix inversion in `numpy` using the following codes:"
      ],
      "metadata": {
        "id": "bZTZ_Uzbg_rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = np.array([\n",
        "    [1,2],\n",
        "    [-1,0]\n",
        "])\n",
        "M_inv = np.linalg.inv(M)\n",
        "M_inv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ucUosBpg6B3",
        "outputId": "6a5fcc95-9424-4aa3-98ac-0fdc8d792f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0. , -1. ],\n",
              "       [ 0.5,  0.5]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M_inv @ M"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nXAIZeWhBDj",
        "outputId": "d35ff7bf-c889-4e8d-9ef2-71ddd2af2b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take note that matrix inversion specifically with `np.linalg.inv()` assumes that the matrix is square. An error will occur when you input a non-square matrix in the function. To resolve this, we turn to the concept of the pseudo-inverse. We will discuss the pseudo-inverse operation further in the later lessons but the main idea is transforming the input matrix $\\mathbf{M}$ into a [positive semi-definite matrix](https://www.youtube.com/watch?v=xsP-S7yKaRA) before performing an inversion. In `numpy`, we can use the following code:"
      ],
      "metadata": {
        "id": "vTqa7x-OhDXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = np.array([\n",
        "    [1,2],\n",
        "    [-1,0],\n",
        "    [1,1]\n",
        "]) ## a non-square matrix\n",
        "M_pinv = np.linalg.pinv(M) ## pseudo-inverse\n",
        "M_pinv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYgx7B7YhCEd",
        "outputId": "bd933931-0ccc-4a2e-bb38-3c5f7f2e3035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.66666667e-01, -8.33333333e-01,  3.33333333e-01],\n",
              "       [ 5.00000000e-01,  5.00000000e-01, -5.64008002e-17]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint Activity 2"
      ],
      "metadata": {
        "id": "pWeKRvhhhGg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System of Linear Equations\n",
        "Solving a system of linear equations is an essential computational technique in engineering. The **system** part of the term refers to a collection of related instances or behavior of entities. These behaviors could be formulated or characterized as **linear equations**. Since this kind of formulation is also a collection of linear transformations, we can also represent it in matrix form."
      ],
      "metadata": {
        "id": "bxJtKD52hHZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Case 2\n",
        "\n",
        "You are a coffee shop owner. For a week you have a quota to sell 650 cups of coffee wherein you have a pre-order of 58 cups from the city hall every Monday. The rest of the week you notice that the average consumption is 100 cups per day. Every week you start with supplies that are approximately 2,800 cups of coffee. You notice your shop produces 200 cups per day.  Will you meet your quota? If so, what day of the week will you meet your quota? If not, what adjustments will you make to meet your quota?"
      ],
      "metadata": {
        "id": "Rxj_MOYPhHcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a supply and demand problem. This problem requires you to determine the individual equations for the supply and demand of coffee. \n",
        "\n",
        "Let's denote the demand equation as $D$.\n",
        "$$D(t)=100t+58$$\n",
        "Where $t$ is time in days and 58 is our starting point every week (Mondays). We now need to determine $t$ to satisfy the equation:\n",
        "$$D(t) = 650$$\n",
        "We can reformulate the equation as:\n",
        "$$100t + 58 = 650$$"
      ],
      "metadata": {
        "id": "tschm8l8hHeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the supply equation. We can denote it as $S$.\n",
        "$$S(t)=-200t+2,800$$\n",
        "Where $t$ is time in days and 2,800 is our initial supply for the week. The rate of consumption is 200 cups per day, we make it negative since our supply should diminish over time. we assume that at the end of the week we will empty out our supplies.\n",
        "$$S(t) = 0$$\n",
        "We can finally reformulate it as:\n",
        "$$-200t+2,800 = 0$$"
      ],
      "metadata": {
        "id": "hAyspYZJhNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now since they are part of a single system we can rewrite the equations as:\n",
        "\n",
        "$$\n",
        "\\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        100t+58=650\\\\ \n",
        "        -200t + 2,800=0\n",
        "    \\end{array}\n",
        "\\right.$$\n",
        "\n",
        "Or using the augmented matrix form:\n",
        "$$\\begin{bmatrix}100&58\\\\-200&2,800\\end{bmatrix} \\cdot \\begin{bmatrix}t\\\\b\\end{bmatrix}=\\begin{bmatrix}650\\\\0\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "S8c_js6PhPD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To solve for the values of $t$ (day of the week) and $b$ (ratio of much coffee we should have for the week) we can solve this using linear algebra using the inverse function:\n",
        "$$ \\begin{bmatrix}t\\\\b\\end{bmatrix}=\\begin{bmatrix}100&58\\\\-200&2,800\\end{bmatrix}^{-1} \\cdot\\begin{bmatrix}650\\\\0\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "uHYju7o9hPG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert the formulation in code:"
      ],
      "metadata": {
        "id": "EutjSec2hTal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D =  np.array([100, 58])\n",
        "S = np.array([-200, 2800])\n",
        "y = np.array([650, 0])\n",
        "X = np.array([D,S])\n",
        "np.linalg.inv(X)@y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlRhwrMxhEhH",
        "outputId": "a2051d99-7248-496a-96e3-83b758a10c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.24142661, 0.44581619])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to our code the resulting vector is $\\begin{bmatrix}6.24&0.44\\end{bmatrix}^T$ which corresponds to our variable array $\\begin{bmatrix}t&b\\end{bmatrix}^T$. Since $t=6.24$ we round it up to the nearest ones so $t=7$, this means that we will meet our quota on Sunday."
      ],
      "metadata": {
        "id": "dxZl0hLRhWUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module Checkpoint"
      ],
      "metadata": {
        "id": "OqiGRQjzhYWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Gramian Matrix\n",
        "A special type of inner product is the inner product between the transpose of a matrix and itself. We can mathematically represent the [Gramian matrix](https://en.wikipedia.org/wiki/Gram_matrix) as:\n",
        "$$G = X^T\\cdot X$$\n",
        "The Gramian/ gram matrix is an important matrix in machine learning. It can be used in several applications such as analysis of parameters in a dataset, a data representation of a dataset, and as a regularization term in regression algorithms."
      ],
      "metadata": {
        "id": "kblNQXYlhaOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a data scientist, you are given the task to do data exploration. You were given a very small dataset resulting from an AB Test for a new formulation of boba milk tea. The data collected only has 5 respondents and two factors were considered: boba texture, tea quality, and sweetness. Instead of integer values, these parameters were converted to continuous float values. You were wierded out but proceeded with the analysis anyways. You wanted to know the level of relatedness of each factors."
      ],
      "metadata": {
        "id": "E_kt9a3xhbFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we split the test data for the A and B test, we would have two $5\\times 3$ matrices.\n",
        "$$A = \\begin{bmatrix}\n",
        "0.67&0.56&0.21\\\\\n",
        "0.78&0.43&0.18\\\\\n",
        "0.44&0.28&0.02\\\\\n",
        "0.88&0.88&0.88 \\\\\n",
        "0.88&0.87&0.83\n",
        "\\end{bmatrix}; \n",
        "B = \\begin{bmatrix}\n",
        "0.89&0.77&0.60\\\\\n",
        "0.90&0.87&0.61\\\\\n",
        "0.74&0.90&0.70\\\\\n",
        "1.0&0.91&0.90\\\\\n",
        "0.88&0.88&0.88\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "L9AK4iiXhcub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([\n",
        "    [0.67, 0.56, 0.21],\n",
        "    [0.78, 0.43, 0.18],\n",
        "    [0.55, 0.32, 0.11],\n",
        "    [0.88, 0.88, 0.88],\n",
        "    [0.88, 0.87, 0.83]\n",
        "])\n",
        "B = np.array([\n",
        "    [0.89, 0.77, 0.60],\n",
        "    [0.90, 0.87, 0.61],\n",
        "    [0.74, 0.90, 0.70],\n",
        "    [1.0, 0.91, 0.90],\n",
        "    [0.88, 0.88, 0.88]\n",
        "])"
      ],
      "metadata": {
        "id": "2i1klaTKhUn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute for the Gramian Matrix of A\n",
        "G_a = A.T@A\n",
        "G_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh1QXvF-hgDu",
        "outputId": "1882cf6b-6016-41d4-e11f-b278afb948f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.9086, 2.4266, 1.8464],\n",
              "       [2.4266, 2.1322, 1.7267],\n",
              "       [1.8464, 1.7267, 1.5519]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you might say that they don't like correlations since the diagonal of the matrix are not high even though they are supposed to be correlations of themselves. To make it similar to the cosine similarity, we would need to divide the matrix with the product of the norms of the features. We can do the following adjustments:"
      ],
      "metadata": {
        "id": "fa3NBGp3hiqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_norms = np.linalg.norm(A, axis=0, keepdims=True)\n",
        "G_a/(A_norms.T @ A_norms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pni2BZEvhhF9",
        "outputId": "c8bec967-3844-4ffa-a7fe-c43cde9b7175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.9744111 , 0.86906433],\n",
              "       [0.9744111 , 1.        , 0.94922912],\n",
              "       [0.86906433, 0.94922912, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZTq1aryhkAl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}